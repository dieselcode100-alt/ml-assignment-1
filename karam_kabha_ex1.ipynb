{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8b1sMpa-BSok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0QiJ-9_BRKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DeFuce89OYBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Student 1: karam: , i.d.:213611213 , https://github.com/dieselcode100-alt\n",
        "Student 2: lamar: , i.d.:214636656 , github:https://github.com/l2amar\n",
        "Student 3: kinda: , i.d.:214576498 , githubhttps://github.com/kabunasra-cmyk"
      ],
      "metadata": {
        "id": "KtraKe7-wRJr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajxBzwOhQIzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load breast cancer dataset (**structured data**)\n",
        "\n",
        "For more details about the data: https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_breast_cancer.html"
      ],
      "metadata": {
        "id": "t1I0ncvTh3x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "my_data = load_breast_cancer()\n",
        "\n"
      ],
      "metadata": {
        "id": "2sS2vcbN3MRc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Split **my_data** to train and test:\n",
        "\n",
        "- Define X_train, X_test, Y_train, Y_test\n",
        "- Choose **test_size** for splitting **my_data**\n",
        "- Use **train_test_split** (for details: https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html)"
      ],
      "metadata": {
        "id": "tCHHt_25iA_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = my_data.data\n",
        "Y = my_data.target\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "!pip install mlflow\n"
      ],
      "metadata": {
        "id": "V8CpCqnGmCg2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0825bd2-9fa2-4f14-f4c2-ae815e3ca2a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.12/dist-packages (3.7.0)\n",
            "Requirement already satisfied: mlflow-skinny==3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.7.0)\n",
            "Requirement already satisfied: mlflow-tracing==3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.7.0)\n",
            "Requirement already satisfied: Flask-CORS<7 in /usr/local/lib/python3.12/dist-packages (from mlflow) (6.0.2)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.12/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: huey<3,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.5.5)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (3.1.2)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.74.0)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.5.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.7.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.4)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.7)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.7.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.7.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.7.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.7.0->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.7.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.7.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.7.0->mlflow) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.7.0->mlflow) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Libraries"
      ],
      "metadata": {
        "id": "bVwASy_zG8Kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
      ],
      "metadata": {
        "id": "trHR283WjwFR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Define MLFlow experiment"
      ],
      "metadata": {
        "id": "v1lvKRu3lCu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPERIMENT_NAME = \"trees_hyperparam\"\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "# MLFlow details: https://mlflow.org/docs/latest/ml/tracking/"
      ],
      "metadata": {
        "id": "lhwmWNz6lIuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4709dbe-86c6-4fe9-e02c-c7c1d1d39395"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/14 09:38:52 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2025/12/14 09:38:52 INFO mlflow.store.db.utils: Updating database tables\n",
            "2025/12/14 09:38:52 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2025/12/14 09:38:52 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2025/12/14 09:38:52 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2025/12/14 09:38:52 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='/content/mlruns/1', creation_time=1765702828230, experiment_id='1', last_update_time=1765702828230, lifecycle_stage='active', name='trees_hyperparam', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train **model_decision_tree**\n",
        "\n",
        "- Library: sklearn.tree.DecisionTreeClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize DecisionTreeClassifier options   "
      ],
      "metadata": {
        "id": "o1_cFF_cjIyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "param_1_list = [\"gini\", \"entropy\", \"log_loss\"]\n",
        "param_2_list = [None, 2, 3, 4, 5, 6, 8, 10]\n",
        "param_3_list = [2, 5, 10, 20]\n",
        "\n",
        "param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))\n",
        "\n",
        "for criterion, max_depth, min_samples_split in param_grid:\n",
        "    with mlflow.start_run():\n",
        "\n",
        "\n",
        "        mlflow.log_param(\"model_type\", \"DecisionTree\")\n",
        "        mlflow.log_param(\"criterion\", criterion)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
        "\n",
        "\n",
        "        d_tree = DecisionTreeClassifier(\n",
        "            criterion=criterion,\n",
        "            max_depth=max_depth,\n",
        "            min_samples_split=min_samples_split,\n",
        "            random_state=42\n",
        "        )\n",
        "        d_tree.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "        y_pred = d_tree.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(Y_test, y_pred)\n",
        "        pre = precision_score(Y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(Y_test, y_pred, zero_division=0)\n",
        "        f1  = f1_score(Y_test, y_pred, zero_division=0)\n",
        "\n",
        "\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision_score\", pre)\n",
        "        mlflow.log_metric(\"recall_score\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n"
      ],
      "metadata": {
        "id": "W8CWNt_2iZm4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train model_random_forest\n",
        "- Library: sklearn.ensemble.RandomForestClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize RandomForestClassifier options"
      ],
      "metadata": {
        "id": "X__nmyElkPWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "param_1_list = [50, 100, 200]\n",
        "param_2_list = [None, 3, 5, 8, 12]\n",
        "param_3_list = [\"sqrt\", \"log2\", None]\n",
        "\n",
        "param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))\n",
        "\n",
        "for n_estimators, max_depth, max_features in param_grid:\n",
        "    with mlflow.start_run():\n",
        "\n",
        "\n",
        "        mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "        mlflow.log_param(\"max_features\", max_features)\n",
        "\n",
        "\n",
        "        rf = RandomForestClassifier(\n",
        "            n_estimators=n_estimators,\n",
        "            max_depth=max_depth,\n",
        "            max_features=max_features,\n",
        "            random_state=42,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        rf.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "        y_pred = rf.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(Y_test, y_pred)\n",
        "        pre = precision_score(Y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(Y_test, y_pred, zero_division=0)\n",
        "        f1  = f1_score(Y_test, y_pred, zero_division=0)\n",
        "\n",
        "\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision_score\", pre)\n",
        "        mlflow.log_metric(\"recall_score\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n"
      ],
      "metadata": {
        "id": "6B4GKjlCkRdT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Train model_adaboost\n",
        "\n",
        "- Library: sklearn.ensemble.AdaBoostClassifier\n",
        "- Data: X_train, Y_train\n",
        "- **Essential**: explore and optimize AdaBoostClassifier options"
      ],
      "metadata": {
        "id": "4qOTlMrDkSBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "param_1_list = [50, 100, 200]\n",
        "param_2_list = [0.01, 0.1, 0.5, 1.0]\n",
        "param_3_list = [1, 2, 3]\n",
        "\n",
        "param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))\n",
        "\n",
        "for n_estimators, learning_rate, est_max_depth in param_grid:\n",
        "    with mlflow.start_run():\n",
        "\n",
        "\n",
        "        mlflow.log_param(\"model_type\", \"AdaBoost\")\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "        mlflow.log_param(\"estimator_max_depth\", est_max_depth)\n",
        "\n",
        "\n",
        "        base_est = DecisionTreeClassifier(max_depth=est_max_depth, random_state=42)\n",
        "\n",
        "\n",
        "        ada = AdaBoostClassifier(\n",
        "            estimator=base_est,\n",
        "            n_estimators=n_estimators,\n",
        "            learning_rate=learning_rate,\n",
        "            random_state=42\n",
        "        )\n",
        "        ada.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "        y_pred = ada.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(Y_test, y_pred)\n",
        "        pre = precision_score(Y_test, y_pred, zero_division=0)\n",
        "        rec = recall_score(Y_test, y_pred, zero_division=0)\n",
        "        f1  = f1_score(Y_test, y_pred, zero_division=0)\n",
        "\n",
        "        # Log metrics\n",
        "        mlflow.log_metric(\"accuracy\", acc)\n",
        "        mlflow.log_metric(\"precision_score\", pre)\n",
        "        mlflow.log_metric(\"recall_score\", rec)\n",
        "        mlflow.log_metric(\"f1_score\", f1)\n"
      ],
      "metadata": {
        "id": "Y5VGaDhJkYsL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Store the result"
      ],
      "metadata": {
        "id": "RryKho_VLGDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "df = mlflow.search_runs(experiment_names=[EXPERIMENT_NAME])\n",
        "\n",
        "df = df.drop(columns=[col for col in df.columns if \"time\" in col.lower()], errors=\"ignore\")\n",
        "df.to_excel(\"karam_kabha_results.xlsx\", index=False)\n",
        "\n",
        "files.download(\"karam_kabha_results.xlsx\")\n"
      ],
      "metadata": {
        "id": "7_-OjeZV2fgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f0ebbe83-7d11-4294-a4e6-974dfdb2ac71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4bf2abd-e869-4c16-90ec-75edb344a21a\", \"karam_kabha_results.xlsx\", 47824)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0pL84NLJUoE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}